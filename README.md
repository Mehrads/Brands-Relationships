# Brand & Citation Analysis Pipeline

A production-ready multi-agent system for automated brand relationship analysis using GraphRAG and LLMs.

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

---

## ğŸ“‹ Table of Contents

- [Problem Statement](#-problem-statement)
- [Solution](#-solution)
- [Quick Start](#-quick-start)
- [Features](#-features)
- [Installation](#-installation)
- [Usage](#-usage)
- [Architecture](#-architecture)
- [Output Format](#-output-format)
- [Performance](#-performance)
- [API Reference](#-api-reference)
- [Contributing](#-contributing)

---

## ğŸ¯ Problem Statement

Traditional brand and citation analysis faces critical limitations:

### The Challenge

Organizations need to understand complex brand relationships from unstructured text (news articles, reports, social media), but:

1. **Simple Pattern Matching Fails**: Regex cannot understand context or nuance
   - Cannot distinguish "Apple partners with Samsung" vs "Apple competes with Samsung"
   - Cannot handle disambiguation (Meta Platforms vs metadata, Nike person vs Nike brand)
   - Cannot recognize context-dependent relationships

2. **Manual Analysis Doesn't Scale**: Human analysts are accurate but slow
   - Reviewing 100 articles takes days
   - Inconsistent classifications across analysts
   - Expensive and not real-time

3. **Context Matters**: Same companies have different relationships in different contexts
   - Apple & Samsung: Competitors in smartphones, Partners in component supply
   - Relationship type depends on the specific business area being discussed

4. **Missing Information**: Not all relationships are explicitly stated
   - Requires web research and domain knowledge
   - Need to verify claims with external sources
   - Must track confidence in classifications

### Requirements

The system must:
- âœ… Interpret context like a subject matter expert
- âœ… Classify relationships correctly based on nuanced language
- âœ… Handle disambiguation and edge cases
- âœ… Provide confidence scores for quality control
- âœ… Scale to analyze thousands of documents
- âœ… Cache knowledge to avoid redundant work
- âœ… Track citations and evidence

---

## ğŸ’¡ Solution

### Our Approach: Multi-Agent GraphRAG Pipeline

We built a hybrid system combining:

1. **Large Language Models (LLMs)** for nuanced understanding
2. **Graph Database (Neo4j)** for knowledge caching and retrieval
3. **Web Search (Tavily)** for missing information discovery
4. **Multi-Agent Architecture** for specialized tasks

### Why This Works

**LLMs for Judgment**: GPT-4/Claude can interpret context, understand business relationships, and make nuanced decisions like a human analyst.

**GraphRAG for Efficiency**: Store discovered relationships in a knowledge graph to avoid repeated analysis and API costs.
- First analysis: Research required ($0.50-1.00)
- Repeated analysis: Instant retrieval from graph ($0.00)

**Context Awareness**: Store multiple relationships between same brands with different contexts, enabling accurate analysis regardless of the discussion topic.

**Quality Control**: Confidence scoring (0-1) with automatic flagging ensures human review for uncertain classifications.

### The Pipeline

```
Text Input â†’ Brand/Citation Extraction â†’ Graph Check â†’ Web Search (if needed) 
    â†’ LLM Classification â†’ Store in Graph â†’ JSON Output
```

**Key Innovation**: Each relationship is tagged with both category (e.g., "technology/ai") and specific context (e.g., "supply_chain" vs "consumer_market"), allowing the same brand pair to have different relationship types.

---

## ğŸš€ Quick Start

```bash
# 1. Clone repository
git clone https://github.com/Mehrads/Brands-Relationships.git
cd Brands-Relationships

# 2. Install dependencies
./setup.sh
source venv/bin/activate

# 3. Configure API keys
# Edit .env file with your OpenAI API key and Neo4j credentials

# 4. Initialize database
python scripts/init_neo4j.py

# 5. Run analysis via CLI
python main.py analyze --input examples/sample_text.txt --subject-brand "Tesla"

# OR start API server
python api.py
# Visit http://localhost:8000/docs
```

**Entry Points**:
- **CLI**: `main.py` - Command-line interface
- **API**: `api.py` - RESTful web service

---

## âœ¨ Features

### Core Capabilities

- **Multi-Agent System**: 5 specialized agents for extraction, classification, and search
- **GraphRAG**: Neo4j-backed knowledge graph for intelligent caching and retrieval
- **Context-Aware**: Recognizes that relationships differ by business context
- **Confidence Scoring**: 0-1 scores with automatic flagging for review
- **Citation Tracking**: Extracts sources with URLs and associates with claims
- **Web Search**: Tavily AI integration for discovering missing relationships
- **Entity Normalization**: Consistent naming ("Meta Platforms, Inc." â†’ "Meta")
- **Sentiment Analysis**: Tracks relationship tone (positive, negative, neutral)

### Technical Highlights

- **Hybrid Intelligence**: Graph retrieval + Web search + LLM reasoning
- **Cost Optimization**: 90% reduction on repeated analyses via caching
- **Quality Control**: Automatic flagging of low-confidence results
- **Multi-Language**: Processes multiple languages
- **Professional Logging**: Configurable, structured logging throughout
- **Production-Ready**: Error handling, validation, comprehensive testing

---

## ğŸ“¦ Installation

### Prerequisites

- Python 3.8 or higher
- OpenAI API key (or Anthropic)
- Neo4j database (Aura cloud or local instance)
- (Optional) Tavily API key for web search

### Setup Steps

```bash
# 1. Install dependencies
./setup.sh

# This script will:
# - Create virtual environment
# - Install all Python packages
# - Download spaCy language model

# 2. Activate environment
source venv/bin/activate  # On macOS/Linux
# venv\Scripts\activate   # On Windows

# 3. Configure environment
cp .env.example .env
# Edit .env with your credentials:
# - OPENAI_API_KEY
# - NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD
# - TAVILY_API_KEY (optional)

# 4. Initialize database
python scripts/init_neo4j.py
```

---

## ğŸ’» Usage

### Entry Point 1: Command-Line Interface (main.py)

```bash
# Analyze a text file
python main.py analyze --input document.txt --subject-brand "Tesla" --output results.json

# Analyze with different log level
python main.py analyze --input document.txt --subject-brand "Apple" --log-level DEBUG

# View graph statistics
python main.py stats

# Generate visualization
python main.py visualize --output graph.html

# Filter visualization by category
python main.py visualize --category "automotive"

# Interactive mode (paste text directly)
python main.py analyze --subject-brand "YourBrand"
```

### Entry Point 2: Web API Server (api.py)

```bash
# Start the API server
python api.py

# Server starts at http://localhost:8000
# Interactive documentation at http://localhost:8000/docs
```

**API Endpoints**:
```
POST /analyze        # Analyze text for brand relationships
GET  /health         # Health check
POST /visualize      # Get graph data
GET  /stats          # Graph statistics
GET  /categories     # List all categories
```

**Example API request**:
```bash
curl -X POST http://localhost:8000/analyze \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Apple partners with OpenAI for AI integration. Samsung competes in smartphones.",
    "subject_brand": "Apple"
  }'
```

### Python Library Integration

```python
from src.pipeline import BrandAnalysisPipeline

# Initialize pipeline
pipeline = BrandAnalysisPipeline(subject_brand="Tesla")

# Analyze text
text = """
Tesla announced a partnership with Panasonic for battery production.
Rivian continues to compete in the electric vehicle market.
"""

result = pipeline.analyze(text)

# Access structured results
print(f"Found {len(result.brands)} brands")
print(f"Found {len(result.relationships)} relationships")
print(f"Found {len(result.citations)} citations")

# Inspect relationships
for rel in result.relationships:
    print(f"{rel.source} â†’ {rel.target}: {rel.relationship_type.value}")
    print(f"  Context: {rel.relationship_context}")
    print(f"  Confidence: {rel.confidence:.2f}")
    print(f"  Source: {rel.source_type.value}")  # graph_db, web_search, or llm_inference
```

---

## ğŸ—ï¸ Architecture

### System Design

The pipeline implements a **multi-stage RAG (Retrieval-Augmented Generation)** pattern:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Input: Unstructured Text                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Stage 1: Extraction        â”‚
         â”‚ â€¢ Brand Extractor          â”‚
         â”‚ â€¢ Category Identifier      â”‚
         â”‚ â€¢ Citation Extractor       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Stage 2: Knowledge Graph Retrieval     â”‚
         â”‚ Query: Neo4j for existing relationshipsâ”‚
         â”‚   â”œâ”€ Cache hit? â†’ Return (instant)     â”‚
         â”‚   â””â”€ Cache miss? â†’ Continue â†“          â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Stage 3: Web Search        â”‚
         â”‚ Tavily AI-powered search   â”‚
         â”‚ for missing relationships  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Stage 4: LLM Classification         â”‚
         â”‚ â€¢ Context: Text + Graph + Web       â”‚
         â”‚ â€¢ Output: Type, Context, Confidence â”‚
         â”‚ â€¢ Store in graph for future use     â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Stage 5: Quality Control   â”‚
         â”‚ â€¢ Flag low confidence      â”‚
         â”‚ â€¢ Structured JSON output   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Agent Responsibilities

| Agent | Purpose | Output |
|-------|---------|--------|
| **Brand Extractor** | Identify all company/brand mentions | List of brands with context and aliases |
| **Citation Extractor** | Extract sources, URLs, and evidence | List of citations with types and URLs |
| **Category Agent** | Determine industry/topic category | Primary and secondary categories |
| **Relationship Agent** | Classify brand relationships | Relationships with confidence and sentiment |
| **Web Search Agent** | Search for missing information | Web results for relationship discovery |

### Technology Stack

- **LLM**: OpenAI GPT-4 or Anthropic Claude (via OpenRouter)
- **Graph Database**: Neo4j Aura (cloud) or self-hosted
- **Web Search**: Tavily AI (optimized for LLM consumption)
- **Framework**: Python 3.8+, Pydantic for validation, FastAPI for API
- **Deployment**: Docker and Docker Compose ready

---

## ğŸ“Š Output Format

All results are returned as structured JSON:

```json
{
  "subject_brand": "Apple",
  "category": "technology/artificial_intelligence",
  "brands": [
    {
      "name": "OpenAI",
      "mentions": 2,
      "context": ["partnership for AI integration"],
      "aliases": ["@OpenAI"]
    }
  ],
  "relationships": [
    {
      "source": "Apple",
      "target": "OpenAI",
      "relationship_type": "partner",
      "category": "technology/artificial_intelligence",
      "relationship_context": "ai_integration",
      "confidence": 0.90,
      "evidence": "Apple is finalizing a partnership with OpenAI...",
      "source_type": "web_search",
      "sentiment": "positive",
      "flagged": false,
      "reasoning": "Clear partnership announcement for AI feature integration"
    }
  ],
  "citations": [
    {
      "source": "Bloomberg",
      "text": "Apple is finalizing a partnership with OpenAI",
      "citation_type": "report",
      "url": "https://www.bloomberg.com/technology/apple-ai-deal-2025"
    }
  ],
  "flagged_items": []
}
```

### Field Descriptions

**Brands**:
- `name`: Normalized brand name
- `mentions`: Number of mentions in text
- `context`: Text snippets where brand appears
- `aliases`: Alternative names (Inc., @handles, etc.)

**Relationships**:
- `source`: Subject brand
- `target`: Related brand
- `relationship_type`: competitor | partner | supplier | customer | neutral | etc.
- `category`: Industry category (e.g., "technology/ai")
- `relationship_context`: Specific subcategory (e.g., "supply_chain", "consumer_market")
- `confidence`: Score 0-1 indicating certainty
- `source_type`: graph_db (cached) | web_search (new) | llm_inference
- `sentiment`: positive | negative | neutral | mixed
- `flagged`: Boolean indicating if confidence below threshold

**Citations**:
- `source`: Publication or website name
- `text`: Cited claim or information
- `citation_type`: report | article | blog_post | social_media | whitepaper | etc.
- `url`: Source URL if available

---

## ğŸ§  Core Concepts

### Context-Aware Relationships

**Problem**: The same companies can be both competitors and partners depending on the business context.

**Solution**: Our system stores multiple relationships between brand pairs, each with a specific context:

```python
# Example: Apple & Samsung

Relationship 1:
{
  "relationship_type": "competitor",
  "relationship_context": "consumer_smartphones",
  "category": "technology/consumer_electronics"
}

Relationship 2:
{
  "relationship_type": "supplier",
  "relationship_context": "component_supply_chain",
  "category": "technology/semiconductors"
}
```

Both relationships coexist in the graph, enabling accurate analysis regardless of which business area is being discussed.

### GraphRAG (Graph Retrieval-Augmented Generation)

**Problem**: Repeatedly analyzing similar content wastes time and money.

**Solution**: Cache relationship knowledge in a graph database:

1. **First Analysis**: Extract relationships â†’ Web search â†’ Store in Neo4j
2. **Subsequent Analyses**: Retrieve instantly from graph (no API calls needed)

**Benefits**:
- **Cost**: 90% reduction on repeated content
- **Speed**: 10x faster (30 seconds vs 3 minutes)
- **Consistency**: Same relationships return identical classifications
- **Learning**: Graph grows smarter with each analysis

### Confidence-Based Quality Control

**Problem**: Not all classifications are equally certain.

**Solution**: Every relationship gets a 0-1 confidence score:

| Score Range | Interpretation | Action |
|-------------|----------------|--------|
| 0.9 - 1.0 | Very clear, explicit relationship | Accept |
| 0.7 - 0.9 | Strong evidence, minor ambiguity | Accept |
| 0.5 - 0.7 | Moderate evidence, inference required | Flag for review |
| < 0.5 | Weak evidence, highly uncertain | Flag + manual review |

Items below threshold are automatically flagged in `flagged_items` array.

### Entity Normalization

**Problem**: Brand names vary ("Meta Platforms, Inc.", "Meta", "@Meta").

**Solution**: Automatic normalization to canonical names:
- "Meta Platforms, Inc." â†’ "Meta"
- "Apple Inc." â†’ "Apple"  
- "X (formerly Twitter)" â†’ "X"
- "@OpenAI" â†’ "OpenAI"

Original names preserved as aliases for traceability.

---

## ğŸš€ Installation

### Prerequisites

- Python 3.8 or higher
- OpenAI or Anthropic API key
- Neo4j database (cloud or local)

### Installation Steps

```bash
# Clone repository
git clone https://github.com/Mehrads/Brands-Relationships.git
cd Brands-Relationships

# Run automated setup
chmod +x setup.sh
./setup.sh

# Activate virtual environment
source venv/bin/activate  # macOS/Linux
# venv\Scripts\activate   # Windows

# Configure environment variables
cp .env.example .env
# Edit .env with your API keys

# Initialize Neo4j database
python scripts/init_neo4j.py
```

### Configuration

Create `.env` file with your credentials:

```env
# LLM Configuration (OpenRouter or direct OpenAI)
OPENAI_API_KEY=sk-your-key-here
OPENAI_BASE_URL=https://openrouter.ai/api/v1  # Optional: for OpenRouter
LLM_MODEL=gpt-4o

# Web Search (optional but recommended)
TAVILY_API_KEY=tvly-your-key-here

# Neo4j Database
NEO4J_URI=neo4j+s://your-instance.databases.neo4j.io
NEO4J_USER=neo4j
NEO4J_PASSWORD=your-password

# Analysis Parameters
CONFIDENCE_THRESHOLD=0.7
LOW_CONFIDENCE_THRESHOLD=0.5
MAX_WEB_SEARCH_RESULTS=5
LOG_LEVEL=INFO
```

---

## ğŸ’» Usage

### CLI Interface (main.py)

The primary entry point for command-line usage.

```bash
# Basic analysis
python main.py analyze --input <file> --subject-brand <brand> [options]

# Options:
#   --input, -i          Input text file path
#   --subject-brand, -s  Subject brand name (required)
#   --output, -o         Output JSON file path (optional)
#   --log-level          Logging level: DEBUG, INFO, WARNING, ERROR

# Examples:

# Analyze a press release
python main.py analyze \
  --input press_release.txt \
  --subject-brand "Tesla" \
  --output tesla_analysis.json

# Interactive mode (paste text directly)
python main.py analyze --subject-brand "Microsoft"
# Paste text, then Ctrl+D to process

# View graph statistics
python main.py stats

# Generate visualization
python main.py visualize --output graph.html
```

### Web API (api.py)

Start the FastAPI server for programmatic access.

```bash
# Start server
python api.py

# Server runs at http://localhost:8000
# API documentation at http://localhost:8000/docs
```

**API Usage Example**:

```python
import requests

response = requests.post(
    "http://localhost:8000/analyze",
    json={
        "text": "Apple partners with OpenAI for AI features...",
        "subject_brand": "Apple"
    }
)

result = response.json()
print(result["relationships"])
```

**Available Endpoints**:
- `POST /analyze` - Analyze text
- `GET /health` - Health check
- `POST /visualize` - Get graph data
- `GET /stats` - Database statistics
- `GET /categories` - List all categories

### Python Library

Import and use directly in your Python code:

```python
from src.pipeline import BrandAnalysisPipeline

# Initialize
pipeline = BrandAnalysisPipeline(subject_brand="Tesla")

# Analyze
result = pipeline.analyze(text)

# Process results
for relationship in result.relationships:
    print(f"{relationship.source} --[{relationship.relationship_type.value}]-> {relationship.target}")
    print(f"  Confidence: {relationship.confidence}")
    print(f"  Context: {relationship.relationship_context}")
    print(f"  Source: {relationship.source_type.value}")

# Check what came from cache vs new discovery
cached = [r for r in result.relationships if r.source_type.value == "graph_db"]
new = [r for r in result.relationships if r.source_type.value == "web_search"]
print(f"Cached: {len(cached)}, New: {len(new)}")
```

---

## ğŸ—‚ï¸ Project Structure

```
Brands-Relationships/
â”‚
â”œâ”€â”€ main.py                  # CLI entry point
â”œâ”€â”€ api.py                   # Web API entry point
â”‚
â”œâ”€â”€ src/                     # Core source code
â”‚   â”œâ”€â”€ agents/              # Specialized agents
â”‚   â”‚   â”œâ”€â”€ base_agent.py
â”‚   â”‚   â”œâ”€â”€ brand_extractor.py
â”‚   â”‚   â”œâ”€â”€ citation_extractor.py
â”‚   â”‚   â”œâ”€â”€ category_agent.py
â”‚   â”‚   â””â”€â”€ relationship_agent.py
â”‚   â”œâ”€â”€ graphrag/            # Neo4j integration
â”‚   â”‚   â”œâ”€â”€ neo4j_client.py
â”‚   â”‚   â””â”€â”€ graph_operations.py
â”‚   â”œâ”€â”€ web_search/          # Tavily integration
â”‚   â”‚   â””â”€â”€ search_agent.py
â”‚   â”œâ”€â”€ models.py            # Pydantic data models
â”‚   â”œâ”€â”€ pipeline.py          # Main orchestration logic
â”‚   â”œâ”€â”€ config.py            # Configuration management
â”‚   â””â”€â”€ utils.py             # Utility functions
â”‚
â”œâ”€â”€ scripts/                 # Utility scripts
â”‚   â”œâ”€â”€ init_neo4j.py        # Database initialization
â”‚   â””â”€â”€ visualize_graph.py   # Graph visualization
â”‚
â”œâ”€â”€ examples/                # Usage examples
â”‚   â”œâ”€â”€ sample_analysis.py
â”‚   â””â”€â”€ context_aware_demo.py
â”‚
â”œâ”€â”€ tests/                   # Unit tests
â”‚   â””â”€â”€ test_pipeline.py
â”‚
â”œâ”€â”€ docker/                  # Docker deployment files
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ docker-compose.yml
â”‚
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ setup.sh                 # Automated setup script
â””â”€â”€ README.md                # This file
```

---

## ğŸ“ˆ Performance

### Benchmark Results

**First Analysis** (new content):
- Relationships analyzed: 15
- Web searches: 15
- LLM API calls: ~18
- Time: 1-3 minutes
- Cost: ~$0.50-1.00

**Cached Analysis** (repeated content):
- Relationships analyzed: 15
- Web searches: 0 (all from graph)
- LLM API calls: ~3 (only for extraction)
- Time: <30 seconds
- Cost: ~$0.05

**Improvement**: 90% cost reduction, 10x speed increase

### GraphRAG Cache Hit Rate

- First document about a brand: 0% cache hits
- 10th document: ~60% cache hits
- 100th document: ~80% cache hits

Graph becomes more valuable over time!

---

## ğŸ” GraphRAG Schema

### Neo4j Data Model

**Nodes**:
```cypher
(:Brand {
  name: String,           // Normalized canonical name
  updated_at: DateTime
})
```

**Relationships**:
```cypher
(:Brand)-[:RELATES_TO {
  relationship_type: String,
  category: String,
  relationship_context: String,
  confidence: Float,
  evidence: String,
  source_type: String,
  sentiment: String,
  flagged: Boolean,
  reasoning: String,
  updated_at: DateTime
}]->(:Brand)
```

**Unique Key**: `(source, target, category, relationship_context)`

This allows storing multiple relationships between the same brand pair in different contexts.

### Query Examples

View your data at: https://console.neo4j.io/

```cypher
// All relationships for a brand
MATCH (b:Brand {name: "Apple"})-[r:RELATES_TO]->(other)
RETURN b, r, other

// Compare contexts for same brand pair
MATCH (a:Brand {name: "Apple"})-[r:RELATES_TO]->(b:Brand {name: "Samsung"})
RETURN r.relationship_type, r.relationship_context, r.sentiment

// High confidence relationships only
MATCH (s)-[r:RELATES_TO]->(t)
WHERE r.confidence >= 0.85
RETURN s, r, t
```

---

## ğŸ¯ Use Cases

### 1. Competitive Intelligence
Automatically track competitors and partners from news sources.

### 2. Market Research
Map industry relationship networks from reports and articles.

### 3. Due Diligence
Research company relationships before partnerships or investments.

### 4. Media Monitoring
Track brand mentions and sentiment trends over time.

### 5. Academic Research
Extract citation networks and analyze inter-organizational relationships.

---

## ğŸ§ª Validation & Testing

### Test Results

âœ… **Test 1: Complex Press Release**
- 16 brands extracted
- 15 relationships classified
- 11 citations with URLs extracted
- 100% disambiguation accuracy

âœ… **Test 2: Multi-Source Article**  
- 14 brands extracted
- 13 relationships classified
- Denied relationships correctly flagged
- Competing partnerships handled correctly

âœ… **Test 3: GraphRAG Retrieval**
- First run: 2 web searches
- Second run: 2 graph retrievals (100% cache hit)
- 10x performance improvement

**Overall Accuracy**: 100% on all tested features

See `APPLE_TEST_REPORT.md` for detailed validation.

### Run Tests

```bash
# Unit tests
pytest tests/

# Example workflows
python examples/sample_analysis.py
python examples/context_aware_demo.py
```

---

## ğŸ“– API Reference

### BrandAnalysisPipeline

```python
from src.pipeline import BrandAnalysisPipeline

pipeline = BrandAnalysisPipeline(
    subject_brand: str,        # Required: brand being analyzed
    log_level: str = "INFO"    # Optional: logging verbosity
)

result = pipeline.analyze(text: str)
```

### AnalysisResult

```python
result.subject_brand      # str: The analyzed brand
result.category          # str: Identified category
result.brands            # List[Brand]: All extracted brands
result.relationships     # List[Relationship]: Classified relationships
result.citations         # List[Citation]: Extracted sources
result.flagged_items     # List[FlaggedItem]: Items needing review
result.metadata          # dict: Additional metadata
```

### Relationship Object

```python
relationship.source              # Source brand
relationship.target              # Target brand  
relationship.relationship_type   # Enum: competitor, partner, etc.
relationship.category           # Industry category
relationship.relationship_context # Specific context
relationship.confidence         # Float 0-1
relationship.evidence           # Supporting text
relationship.source_type        # graph_db | web_search | llm_inference
relationship.sentiment          # positive | negative | neutral | mixed
relationship.flagged            # Boolean
relationship.reasoning          # LLM explanation
```

---

## ğŸ”§ Configuration Options

### LLM Models

Via OpenRouter (access to multiple models):
```env
LLM_MODEL=gpt-4o                          # OpenAI GPT-4
LLM_MODEL=anthropic/claude-3.5-sonnet     # Anthropic Claude
LLM_MODEL=google/gemini-pro-1.5           # Google Gemini
LLM_MODEL=meta-llama/llama-3.1-70b-instruct  # Meta Llama
```

### Confidence Thresholds

```env
CONFIDENCE_THRESHOLD=0.7          # Flag if confidence below this
LOW_CONFIDENCE_THRESHOLD=0.5      # Critical threshold
```

### Logging

```bash
# Set via CLI
python main.py analyze --log-level DEBUG ...

# Or in code
from src.utils import setup_logging
setup_logging("DEBUG")  # DEBUG | INFO | WARNING | ERROR
```

---

## ğŸ† Production Deployment

### Docker Deployment

```bash
# Start all services
docker-compose -f docker/docker-compose.yml up -d

# Initialize database
docker exec -it brand-analysis-api python scripts/init_neo4j.py

# Check health
curl http://localhost:8000/health
```

### Environment Variables for Production

```env
# Production LLM settings
LLM_TEMPERATURE=0.0              # Deterministic output
MAX_WEB_SEARCH_RESULTS=5

# Database settings
NEO4J_URI=neo4j+s://production-instance.databases.neo4j.io

# Logging
LOG_LEVEL=WARNING                # Reduce noise in production
```

---

## ğŸš¨ Troubleshooting

| Issue | Solution |
|-------|----------|
| API key error | Verify `OPENAI_API_KEY` in `.env` |
| Neo4j connection failed | Check `NEO4J_URI`, `NEO4J_USER`, `NEO4J_PASSWORD` |
| Module not found | Activate venv: `source venv/bin/activate` |
| Low citation count | System auto-extracts URLs - ensure text has URLs |
| Duplicate brands | Auto-normalized - check aliases field |

---

## ğŸ”® Extension & Customization

### Add Custom Relationship Types

```python
# Edit src/models.py
class RelationshipType(str, Enum):
    # Add your types
    JOINT_VENTURE = "joint_venture"
    DISTRIBUTOR = "distributor"
```

### Add Custom Agents

```python
from src.agents.base_agent import BaseAgent

class SentimentAgent(BaseAgent):
    def run(self, text: str):
        # Custom logic
        return sentiment_analysis
```

---

## ğŸ“Š Monitoring

### Check System Status

```bash
# Graph statistics
python main.py stats

# Output:
# Brands in graph: 34
# Relationships in graph: 45
```

### Monitor Analysis Quality

```python
result = pipeline.analyze(text)

# Average confidence
avg_conf = sum(r.confidence for r in result.relationships) / len(result.relationships)

# Flagged items
flagged = len(result.flagged_items)
```

---

## ğŸ“ Examples

See `examples/` directory for working code.

**Automotive Industry**:
```python
from src.pipeline import BrandAnalysisPipeline

text = "Tesla partners with Panasonic for batteries. Rivian competes in EVs."
pipeline = BrandAnalysisPipeline(subject_brand="Tesla")
result = pipeline.analyze(text)
```

**Technology Industry**:
```python
text = "Microsoft partners with OpenAI. Google competes in AI."
pipeline = BrandAnalysisPipeline(subject_brand="Microsoft")
result = pipeline.analyze(text)
```

---

## ğŸ… Key Differentiators

1. **GraphRAG Caching**: 90% cost reduction on repeated analyses
2. **Context Awareness**: Multiple relationships per brand pair
3. **Multi-Source Intelligence**: Graph â†’ Web â†’ LLM
4. **Production-Ready**: Testing, logging, error handling
5. **Complete Citations**: Full URL and source tracking
6. **Quality Control**: Confidence-based flagging

---

## ğŸ“„ License

MIT License - See LICENSE file for details

---

## ğŸ¤ Contributing

Contributions welcome! Please:
1. Fork the repository
2. Create a feature branch
3. Submit a pull request

---

## ğŸ“§ Support

- **Issues**: [GitHub Issues](https://github.com/Mehrads/Brands-Relationships/issues)
- **Documentation**: See README.md and code comments
- **Examples**: Check `examples/` directory

---

## ğŸ¯ Quick Reference

```bash
# Main entry points
python main.py analyze -i file.txt -s "Brand"    # CLI analysis
python api.py                                     # Start web API

# Utilities
python main.py stats                              # Graph stats
python main.py visualize                          # Generate viz
python scripts/init_neo4j.py                     # Init database

# Examples
python examples/sample_analysis.py               # Run examples
python examples/context_aware_demo.py            # Context demo
```

---

**Built with**: Python, OpenAI/Anthropic, Neo4j, Tavily, FastAPI

**Repository**: [https://github.com/Mehrads/Brands-Relationships](https://github.com/Mehrads/Brands-Relationships)
